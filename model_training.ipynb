{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:24.142343Z",
          "iopub.status.busy": "2025-03-13T20:02:24.142020Z",
          "iopub.status.idle": "2025-03-13T20:02:24.348281Z",
          "shell.execute_reply": "2025-03-13T20:02:24.347399Z",
          "shell.execute_reply.started": "2025-03-13T20:02:24.142320Z"
        },
        "id": "6dLWnK2H3WGa",
        "outputId": "493f862a-14e8-4f63-d54f-1b3bc9ca1c89",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Mar 14 15:25:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 570.124.04             Driver Version: 570.124.04     CUDA Version: 12.8     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA RTX 4000 Ada Gene...    Off |   00000000:01:00.0  On |                  Off |\n",
            "| 30%   31C    P8             14W /  130W |    1069MiB /  20475MiB |     35%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A         2573616      G   /usr/libexec/Xorg                       278MiB |\n",
            "|    0   N/A  N/A         2573731      G   /usr/bin/gnome-shell                     87MiB |\n",
            "|    0   N/A  N/A         2574785      G   /usr/lib64/firefox/firefox              517MiB |\n",
            "|    0   N/A  N/A         2575666      G   ...ess --variations-seed-version        122MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:31.031384Z",
          "iopub.status.busy": "2025-03-13T20:02:31.031077Z",
          "iopub.status.idle": "2025-03-13T20:02:37.606089Z",
          "shell.execute_reply": "2025-03-13T20:02:37.604918Z",
          "shell.execute_reply.started": "2025-03-13T20:02:31.031362Z"
        },
        "id": "EPb7FrW1DtrZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -qqq bitsandbytes torch transformers peft accelerate datasets loralib einops trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:46.525557Z",
          "iopub.status.busy": "2025-03-13T20:02:46.525223Z",
          "iopub.status.idle": "2025-03-13T20:02:49.224561Z",
          "shell.execute_reply": "2025-03-13T20:02:49.223716Z",
          "shell.execute_reply.started": "2025-03-13T20:02:46.525529Z"
        },
        "id": "yeoLzl8oDnkx",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/eleves-a/2024/christelle.clervilsson/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/usr/lib64/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T20:04:41.102714Z",
          "iopub.status.busy": "2025-03-13T20:04:41.102400Z",
          "iopub.status.idle": "2025-03-13T20:04:41.442423Z",
          "shell.execute_reply": "2025-03-13T20:04:41.441362Z",
          "shell.execute_reply.started": "2025-03-13T20:04:41.102682Z"
        },
        "id": "jhnddYVK3MtZ",
        "outputId": "790112fa-2909-4d1d-dd80-bef98d33fdbe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "bnb_config = {\n",
        "    \"load_in_4bit\": True,  \n",
        "    \"bnb_4bit_compute_dtype\": torch.float16,  # Ensure computation is done in float16\n",
        "    \"torch_dtype\": torch.float16,  # Use float16 for computation\n",
        "    \"device_map\": \"auto\",  \n",
        "    \"llm_int8_enable_fp32_cpu_offload\": True, \n",
        "}\n",
        "model_name_I= \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:04:52.682309Z",
          "iopub.status.busy": "2025-03-13T20:04:52.681989Z",
          "iopub.status.idle": "2025-03-13T20:04:52.839685Z",
          "shell.execute_reply": "2025-03-13T20:04:52.838535Z",
          "shell.execute_reply.started": "2025-03-13T20:04:52.682290Z"
        },
        "id": "Num_web8EkY9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc_in\", \"fc_out\", \"wte\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5GFzNHRI03O",
        "outputId": "0d3dad03-7108-4f1d-e0c8-bef8c236712f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " R√©sumez cet article \n",
            "<article>: Deux images, et un sujet central : l‚ÄôUkraine. La journ√©e du jeudi 13 mars a √©t√© marqu√©e par un dialogue public √† distance entre Vladimir Poutine et Donald Trump. Accueillant √† Moscou son homologue bi√©lorusse, Alexandre Loukachenko, le pr√©sident russe a acquiesc√© du bout des l√®vres, et sous conditions, √† la proposition de cessez-le-feu de trente jours, avanc√©e par la Maison Blanche et valid√©e par Kiev. Pendant ce temps, √† Washington, Donald Trump recevait le secr√©taire g√©n√©ral de l‚ÄôOTAN, Mark Rutte. Le rapprochement am√©ricano-russe et l‚Äôacception conditionn√©e de la solidarit√© entre alli√©s, pris√©e par le milliardaire, inqui√®tent fortement les membres europ√©ens de l‚ÄôAlliance atlantique. Au terme de cette journ√©e, ni la paix en Ukraine ni l‚Äôavenir de l‚ÄôOTAN ne se dessinent plus clairement.\n",
            "<r√©sum√©>:\n"
          ]
        }
      ],
      "source": [
        "prompt=\" R√©sumez cet article \\n<article>: Deux images, et un sujet central : l‚ÄôUkraine. La journ√©e du jeudi 13 mars a √©t√© marqu√©e par un dialogue public √† distance entre Vladimir Poutine et Donald Trump. Accueillant √† Moscou son homologue bi√©lorusse, Alexandre Loukachenko, le pr√©sident russe a acquiesc√© du bout des l√®vres, et sous conditions, √† la proposition de cessez-le-feu de trente jours, avanc√©e par la Maison Blanche et valid√©e par Kiev. Pendant ce temps, √† Washington, Donald Trump recevait le secr√©taire g√©n√©ral de l‚ÄôOTAN, Mark Rutte. Le rapprochement am√©ricano-russe et l‚Äôacception conditionn√©e de la solidarit√© entre alli√©s, pris√©e par le milliardaire, inqui√®tent fortement les membres europ√©ens de l‚ÄôAlliance atlantique. Au terme de cette journ√©e, ni la paix en Ukraine ni l‚Äôavenir de l‚ÄôOTAN ne se dessinent plus clairement.\\n<r√©sum√©>:\"\n",
        "print(prompt)\n",
        "\n",
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config.do_sample = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jpBcRaNJ2Xv",
        "outputId": "ad66af68-82e0-48c6-8fbb-bbdfd4d0f98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " R√©sumez cet article \n",
            "<article>: Deux images, et un sujet central : l‚ÄôUkraine. La journ√©e du jeudi 13 mars a √©t√© marqu√©e par un dialogue public √† distance entre Vladimir Poutine et Donald Trump. Accueillant √† Moscou son homologue bi√©lorusse, Alexandre Loukachenko, le pr√©sident russe a acquiesc√© du bout des l√®vres, et sous conditions, √† la proposition de cessez-le-feu de trente jours, avanc√©e par la Maison Blanche et valid√©e par Kiev. Pendant ce temps, √† Washington, Donald Trump recevait le secr√©taire g√©n√©ral de l‚ÄôOTAN, Mark Rutte. Le rapprochement am√©ricano-russe et l‚Äôacception conditionn√©e de la solidarit√© entre alli√©s, pris√©e par le milliardaire, inqui√®tent fortement les membres europ√©ens de l‚ÄôAlliance atlantique. Au terme de cette journ√©e, ni la paix en Ukraine ni l‚Äôavenir de l‚ÄôOTAN ne se dessinent plus clairement.\n",
            "<r√©sum√©>: C'est une histoire d'histoire politique qui d√©marre avec l'entr√©e au pouvoir de Vladimir Poutine, le 24 janvier 2015, dans l'√©meute de l'URSS, et qui s'acheit avec la signature du accord de cesser le conflit √† Moscou, et la signature du pacte de solidarit√© pour l'Europe. L'accent est mis sur la place de la Russie dans l'alliance europ√©enne, dont l'image de p√©titionur, et sur la situation √©conomique de l'UE. Dans l'objectif de cette histoire, la Russie reste √† l'avantage strat√©gique, car elle est √† la fois un p√©tionnaire et un p√©titionier, et comme l'a fait remarquer la France, il y a une relation commerciale entre l'URSS et l'URSS. Il existe deux autres sources de soutien : la France, qui est √† l\n",
            "CPU times: user 2.3 s, sys: 2.13 ms, total: 2.3 s\n",
            "Wall time: 2.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:22:28.873416Z",
          "iopub.status.busy": "2025-03-13T19:22:28.873098Z",
          "iopub.status.idle": "2025-03-13T19:22:35.047639Z",
          "shell.execute_reply": "2025-03-13T19:22:35.046798Z",
          "shell.execute_reply.started": "2025-03-13T19:22:28.873396Z"
        },
        "id": "AtRdYaIO5bow",
        "outputId": "c5049009-2689-42aa-a50a-566391e0bdce",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set: 4000 examples\n",
            "Validation Set: 500 examples\n",
            "Test Set: 500 examples\n"
          ]
        }
      ],
      "source": [
        "ds = pd.read_csv(\"summary_dataset.csv\")\n",
        "train_ds, temp_ds = ds.train_test_split(test_size=0.2).values()  # 80% train, 20% temp\n",
        "valid_ds, test_ds = temp_ds.train_test_split(test_size=0.5).values()  # Split temp into 50% validation, 50% test\n",
        "\n",
        "\n",
        "# Display the number of examples in each split\n",
        "print(f\"Training Set: {len(train_ds)} examples\")\n",
        "print(f\"Validation Set: {len(valid_ds)} examples\")\n",
        "print(f\"Test Set: {len(test_ds)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [17:46<00:00,  2.13s/ examples]\n",
            "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.77ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3212241"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summary(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \" R√©sumez cet article \\n<article>: \"+prompt+ \"\\n<r√©sum√©>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-no-shot'] = summary\n",
        "    return example\n",
        "\n",
        "# Iterate over the dataset and generate summaries\n",
        "test_ds=test_ds.map(generate_summary)\n",
        "# Save the modified dataset with the new column\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_noshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [16:41<00:00,  2.00s/ examples]\n",
            "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.87ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5149558"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryO(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \"Voici l'exemples d' un article et son r√©sum√© :\\n Article : Un r√©seau d'escrocs qui revendait des voitures de luxe achet√©es frauduleusement a √©t√© d√©mantel√©. L'op√©ration a mobilis√© 90 gendarmes en Gironde, dans le Var et les Pyr√©n√©es-Orientales. Dix suspects ont √©t√© arr√™t√©s, avec un pr√©judice total de 2 millions d'euros.\\n R√©sum√© : Dix personnes arr√™t√©es apr√®s une enqu√™te sur une escroquerie aux voitures de luxe, causant un pr√©judice de 2 millions d‚Äôeuros.\\nMaintenant r√©sumez cet article \\n<article>: \"+prompt+ \"\\n<r√©sum√©>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-one-shot'] = summary\n",
        "    return example\n",
        "test_ds=test_ds.map(generate_summaryO)\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_oneshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [15:22<00:00,  1.85s/ examples]\n",
            "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.20ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7236904"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryF(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \"Voici des exemples d'articles et leurs r√©sum√©s : \\nArticle : Un r√©seau d'escrocs qui revendait des voitures de luxe achet√©es frauduleusement a √©t√© d√©mantel√©. L'op√©ration a mobilis√© 90 gendarmes en Gironde, dans le Var et les Pyr√©n√©es-Orientales. Dix suspects ont √©t√© arr√™t√©s, avec un pr√©judice total de 2 millions d'euros. \\n R√©sum√© : Dix personnes arr√™t√©es apr√®s une enqu√™te sur une escroquerie aux voitures de luxe, causant un pr√©judice de 2 millions d‚Äôeuros. \\n Article : La saison 7 de Danse avec les stars s'est termin√©e, mais la saison 8 pourrait voir un changement majeur. Marie-Claude Pietragalla, juge depuis 2012, a indiqu√© qu'elle pourrait ne pas revenir en raison d'un emploi du temps charg√©. \\n R√©sum√© :  Marie-Claude Pietragalla pourrait quitter Danse avec les stars avant la saison 8. \\n Maintenant, r√©sumez cet article \\n<article>: \"+prompt+ \"\\n<r√©sum√©>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-few-shot'] = summary\n",
        "    return example\n",
        "test_ds=test_ds.map(generate_summaryF)\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_fewshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "caa6ca5074524b3bae5c8667a9930521",
            "047a977317f64641839e2d861fce9730",
            "4cbb1d7a496d41179d3bacde7a551563",
            "b12fc8b7eb6b463a817991002b43c261",
            "8a5ff2881388447eb1aba2e3f7766a29",
            "4eeb409d7a184a0494413d679e634281",
            "53bf697901c54486a43346083b6f5285",
            "4f7b44a7c46b4ae69b6af33c5e94ef45",
            "a43f0fa14008411885d60700ff1957d0",
            "8e2a146d4bbf4c49b35c29885339cb8b",
            "6a00d3e34d8845c9a500094c97db08d4",
            "446820aff94d4439ad2900251021d9cc",
            "f126dad02865462a84b27bd53e06a320",
            "3d58d5037dc54b1db37f7b9f58e2465a",
            "39a1b029dc3e4e61905324c2d0a0bcad",
            "4744462f25bb43b988269fdd1ab5e5d4",
            "3ca111d692fc4bed8d5e334e716b026a",
            "3b65c7213baa4a2586657e991751ac99",
            "b67893fb4aab4e06b204711c385543ac",
            "643bf294f441452fa12e23d52d7f751b",
            "7bc5197a69e74ecf8ea9848889bcb9ab",
            "37dd673aca5c4e7ab573fdc68a341f76"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:23:59.098340Z",
          "iopub.status.busy": "2025-03-13T19:23:59.098027Z",
          "iopub.status.idle": "2025-03-13T19:24:05.775480Z",
          "shell.execute_reply": "2025-03-13T19:24:05.774780Z",
          "shell.execute_reply.started": "2025-03-13T19:23:59.098315Z"
        },
        "id": "O6g5ncU84tUC",
        "outputId": "a9488a47-dff5-4465-8512-266f9ef14a98",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [00:07<00:00, 547.00 examples/s]\n",
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 559.97 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = f\"R√©sumez cet article,\\n<article>: {data_point['text']}\\n<r√©sum√©>:\"\n",
        "    response = f\" {data_point['generated-summary']}\"  \n",
        "\n",
        "    full_prompt_with_response = full_prompt + response + tokenizer.eos_token  # Append response + EOS token\n",
        "    tokenized_full_prompt = tokenizer(\n",
        "        full_prompt_with_response,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "        max_length=512\n",
        "    )\n",
        "    labels = tokenized_full_prompt.input_ids.clone()\n",
        "    end_prompt_idx = len(tokenizer(full_prompt)['input_ids']) \n",
        "    labels[:, :end_prompt_idx] = -100\n",
        "    return {\n",
        "        'input_ids': tokenized_full_prompt.input_ids.flatten(),\n",
        "        'labels': labels.flatten(),\n",
        "        'attention_mask': tokenized_full_prompt.attention_mask.flatten(),\n",
        "    }\n",
        "train_dataset = train_ds.shuffle(seed=42).map(generate_and_tokenize_prompt)\n",
        "val_dataset=valid_ds.shuffle(seed=42).map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T19:30:14.955887Z",
          "iopub.status.busy": "2025-03-13T19:30:14.955430Z",
          "iopub.status.idle": "2025-03-13T19:30:14.959717Z",
          "shell.execute_reply": "2025-03-13T19:30:14.958810Z",
          "shell.execute_reply.started": "2025-03-13T19:30:14.955850Z"
        },
        "id": "bL41MwIm6V4I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:33:11.358356Z",
          "iopub.status.busy": "2025-03-13T19:33:11.358064Z",
          "iopub.status.idle": "2025-03-13T19:33:12.957427Z",
          "shell.execute_reply": "2025-03-13T19:33:12.955903Z",
          "shell.execute_reply.started": "2025-03-13T19:33:11.358337Z"
        },
        "id": "noQU1h9k5djr",
        "outputId": "e0aa03fd-27e3-4e2d-e815-ca921b3d3c3a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/eleves-a/2024/christelle.clervilsson/.local/lib/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipykernel_2576282/4172712129.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 09:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.967800</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.301100</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.131900</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=750, training_loss=2.364438761393229, metrics={'train_runtime': 576.1801, 'train_samples_per_second': 20.827, 'train_steps_per_second': 1.302, 'total_flos': 1.3302272360448e+16, 'train_loss': 2.364438761393229, 'epoch': 3.0})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir='./results',\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    adam_epsilon=1e-8,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.999,\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=500,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='loss',\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "\n",
        ")\n",
        "model.config.use_cache = False\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEGzXnsWv_Dx",
        "outputId": "66a7384c-83c5-4c02-8c49-476a84d02f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./saved_model23_tokenizer-Instruct/tokenizer_config.json',\n",
              " './saved_model23_tokenizer-Instruct/special_tokens_map.json',\n",
              " './saved_model23_tokenizer-Instruct/vocab.json',\n",
              " './saved_model23_tokenizer-Instruct/merges.txt',\n",
              " './saved_model23_tokenizer-Instruct/added_tokens.json',\n",
              " './saved_model23_tokenizer-Instruct/tokenizer.json')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"./saved_model23\")\n",
        "tokenizer.save_pretrained(\"./saved_model23_tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Oz7tREn87glX"
      },
      "outputs": [],
      "source": [
        "prompt=\" R√©sumez cet article \\n<article>: Deux images, et un sujet central : l‚ÄôUkraine. La journ√©e du jeudi 13 mars a √©t√© marqu√©e par un dialogue public √† distance entre Vladimir Poutine et Donald Trump. Accueillant √† Moscou son homologue bi√©lorusse, Alexandre Loukachenko, le pr√©sident russe a acquiesc√© du bout des l√®vres, et sous conditions, √† la proposition de cessez-le-feu de trente jours, avanc√©e par la Maison Blanche et valid√©e par Kiev. Pendant ce temps, √† Washington, Donald Trump recevait le secr√©taire g√©n√©ral de l‚ÄôOTAN, Mark Rutte. Le rapprochement am√©ricano-russe et l‚Äôacception conditionn√©e de la solidarit√© entre alli√©s, pris√©e par le milliardaire, inqui√®tent fortement les membres europ√©ens de l‚ÄôAlliance atlantique. Au terme de cette journ√©e, ni la paix en Ukraine ni l‚Äôavenir de l‚ÄôOTAN ne se dessinent plus clairement.\\n<r√©sum√©>:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRQZFfyP7fQO",
        "outputId": "cf7c3ea8-bf71-4ba9-987f-530ccd62de2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " R√©sumez cet article \n",
            "<article>: Deux images, et un sujet central : l‚ÄôUkraine. La journ√©e du jeudi 13 mars a √©t√© marqu√©e par un dialogue public √† distance entre Vladimir Poutine et Donald Trump. Accueillant √† Moscou son homologue bi√©lorusse, Alexandre Loukachenko, le pr√©sident russe a acquiesc√© du bout des l√®vres, et sous conditions, √† la proposition de cessez-le-feu de trente jours, avanc√©e par la Maison Blanche et valid√©e par Kiev. Pendant ce temps, √† Washington, Donald Trump recevait le secr√©taire g√©n√©ral de l‚ÄôOTAN, Mark Rutte. Le rapprochement am√©ricano-russe et l‚Äôacception conditionn√©e de la solidarit√© entre alli√©s, pris√©e par le milliardaire, inqui√®tent fortement les membres europ√©ens de l‚ÄôAlliance atlantique. Au terme de cette journ√©e, ni la paix en Ukraine ni l‚Äôavenir de l‚ÄôOTAN ne se dessinent plus clairement.\n",
            "<r√©sum√©>: Le 13 mars 2021, le pr√©sident russe Vladimir Poutine a d√©clar√© √† Washington que la Ukraine serait ¬´ d√©ploy√©e √† la fronti√®re de l‚ÄôEurope ¬ª. Le Kremlin a pr√©sent√© la cessez-le-feu de trente jours comme une garantie de paix. La Maison Blanche a accept√© la proposition de cessez-le-feu, mais ne s‚Äôest pas rendu compte de la solidarit√© entre alli√©s. Le pr√©sident russe a d√©clar√© que la Ukraine √©tait ¬´ d√©ploy√©e √† la fronti√®re de l‚ÄôEurope ¬ª et que la Russie √©tait ¬´ √† la fronti√®re de l‚ÄôEurope ¬ª.\n",
            "CPU times: user 1.65 s, sys: 5.06 ms, total: 1.66 s\n",
            "Wall time: 1.66 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOfD-Glc9ItN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [19:41<00:00,  2.36s/ examples]\n",
            "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.20ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3256199"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryFT(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \" R√©sumez cet article \\n<article>: \"+prompt+ \"\\n<r√©sum√©>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['current-summary'] = summary\n",
        "    return example\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "test_ds=test_ds.map(generate_summaryFT)\n",
        "test_ds.to_csv(\"orangesum_with_summary_afterfinetuning-Instruct.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "047a977317f64641839e2d861fce9730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eeb409d7a184a0494413d679e634281",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53bf697901c54486a43346083b6f5285",
            "value": "Map:‚Äá100%"
          }
        },
        "37dd673aca5c4e7ab573fdc68a341f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a1b029dc3e4e61905324c2d0a0bcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc5197a69e74ecf8ea9848889bcb9ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37dd673aca5c4e7ab573fdc68a341f76",
            "value": "‚Äá500/500‚Äá[00:03&lt;00:00,‚Äá145.68‚Äáexamples/s]"
          }
        },
        "3b65c7213baa4a2586657e991751ac99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ca111d692fc4bed8d5e334e716b026a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d58d5037dc54b1db37f7b9f58e2465a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67893fb4aab4e06b204711c385543ac",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_643bf294f441452fa12e23d52d7f751b",
            "value": 500
          }
        },
        "446820aff94d4439ad2900251021d9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f126dad02865462a84b27bd53e06a320",
              "IPY_MODEL_3d58d5037dc54b1db37f7b9f58e2465a",
              "IPY_MODEL_39a1b029dc3e4e61905324c2d0a0bcad"
            ],
            "layout": "IPY_MODEL_4744462f25bb43b988269fdd1ab5e5d4"
          }
        },
        "4744462f25bb43b988269fdd1ab5e5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbb1d7a496d41179d3bacde7a551563": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7b44a7c46b4ae69b6af33c5e94ef45",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43f0fa14008411885d60700ff1957d0",
            "value": 4000
          }
        },
        "4eeb409d7a184a0494413d679e634281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7b44a7c46b4ae69b6af33c5e94ef45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bf697901c54486a43346083b6f5285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "643bf294f441452fa12e23d52d7f751b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a00d3e34d8845c9a500094c97db08d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc5197a69e74ecf8ea9848889bcb9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5ff2881388447eb1aba2e3f7766a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2a146d4bbf4c49b35c29885339cb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43f0fa14008411885d60700ff1957d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b12fc8b7eb6b463a817991002b43c261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e2a146d4bbf4c49b35c29885339cb8b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a00d3e34d8845c9a500094c97db08d4",
            "value": "‚Äá4000/4000‚Äá[00:29&lt;00:00,‚Äá130.82‚Äáexamples/s]"
          }
        },
        "b67893fb4aab4e06b204711c385543ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa6ca5074524b3bae5c8667a9930521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_047a977317f64641839e2d861fce9730",
              "IPY_MODEL_4cbb1d7a496d41179d3bacde7a551563",
              "IPY_MODEL_b12fc8b7eb6b463a817991002b43c261"
            ],
            "layout": "IPY_MODEL_8a5ff2881388447eb1aba2e3f7766a29"
          }
        },
        "f126dad02865462a84b27bd53e06a320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca111d692fc4bed8d5e334e716b026a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3b65c7213baa4a2586657e991751ac99",
            "value": "Map:‚Äá100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

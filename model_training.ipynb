{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:24.142343Z",
          "iopub.status.busy": "2025-03-13T20:02:24.142020Z",
          "iopub.status.idle": "2025-03-13T20:02:24.348281Z",
          "shell.execute_reply": "2025-03-13T20:02:24.347399Z",
          "shell.execute_reply.started": "2025-03-13T20:02:24.142320Z"
        },
        "id": "6dLWnK2H3WGa",
        "outputId": "493f862a-14e8-4f63-d54f-1b3bc9ca1c89",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Mar 14 15:25:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 570.124.04             Driver Version: 570.124.04     CUDA Version: 12.8     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA RTX 4000 Ada Gene...    Off |   00000000:01:00.0  On |                  Off |\n",
            "| 30%   31C    P8             14W /  130W |    1069MiB /  20475MiB |     35%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A         2573616      G   /usr/libexec/Xorg                       278MiB |\n",
            "|    0   N/A  N/A         2573731      G   /usr/bin/gnome-shell                     87MiB |\n",
            "|    0   N/A  N/A         2574785      G   /usr/lib64/firefox/firefox              517MiB |\n",
            "|    0   N/A  N/A         2575666      G   ...ess --variations-seed-version        122MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:31.031384Z",
          "iopub.status.busy": "2025-03-13T20:02:31.031077Z",
          "iopub.status.idle": "2025-03-13T20:02:37.606089Z",
          "shell.execute_reply": "2025-03-13T20:02:37.604918Z",
          "shell.execute_reply.started": "2025-03-13T20:02:31.031362Z"
        },
        "id": "EPb7FrW1DtrZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -qqq bitsandbytes torch transformers peft accelerate datasets loralib einops trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:02:46.525557Z",
          "iopub.status.busy": "2025-03-13T20:02:46.525223Z",
          "iopub.status.idle": "2025-03-13T20:02:49.224561Z",
          "shell.execute_reply": "2025-03-13T20:02:49.223716Z",
          "shell.execute_reply.started": "2025-03-13T20:02:46.525529Z"
        },
        "id": "yeoLzl8oDnkx",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/eleves-a/2024/christelle.clervilsson/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/usr/lib64/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T20:04:41.102714Z",
          "iopub.status.busy": "2025-03-13T20:04:41.102400Z",
          "iopub.status.idle": "2025-03-13T20:04:41.442423Z",
          "shell.execute_reply": "2025-03-13T20:04:41.441362Z",
          "shell.execute_reply.started": "2025-03-13T20:04:41.102682Z"
        },
        "id": "jhnddYVK3MtZ",
        "outputId": "790112fa-2909-4d1d-dd80-bef98d33fdbe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "bnb_config = {\n",
        "    \"load_in_4bit\": True,  \n",
        "    \"bnb_4bit_compute_dtype\": torch.float16,  # Ensure computation is done in float16\n",
        "    \"torch_dtype\": torch.float16,  # Use float16 for computation\n",
        "    \"device_map\": \"auto\",  \n",
        "    \"llm_int8_enable_fp32_cpu_offload\": True, \n",
        "}\n",
        "model_name_I= \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T20:04:52.682309Z",
          "iopub.status.busy": "2025-03-13T20:04:52.681989Z",
          "iopub.status.idle": "2025-03-13T20:04:52.839685Z",
          "shell.execute_reply": "2025-03-13T20:04:52.838535Z",
          "shell.execute_reply.started": "2025-03-13T20:04:52.682290Z"
        },
        "id": "Num_web8EkY9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc_in\", \"fc_out\", \"wte\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5GFzNHRI03O",
        "outputId": "0d3dad03-7108-4f1d-e0c8-bef8c236712f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Résumez cet article \n",
            "<article>: Deux images, et un sujet central : l’Ukraine. La journée du jeudi 13 mars a été marquée par un dialogue public à distance entre Vladimir Poutine et Donald Trump. Accueillant à Moscou son homologue biélorusse, Alexandre Loukachenko, le président russe a acquiescé du bout des lèvres, et sous conditions, à la proposition de cessez-le-feu de trente jours, avancée par la Maison Blanche et validée par Kiev. Pendant ce temps, à Washington, Donald Trump recevait le secrétaire général de l’OTAN, Mark Rutte. Le rapprochement américano-russe et l’acception conditionnée de la solidarité entre alliés, prisée par le milliardaire, inquiètent fortement les membres européens de l’Alliance atlantique. Au terme de cette journée, ni la paix en Ukraine ni l’avenir de l’OTAN ne se dessinent plus clairement.\n",
            "<résumé>:\n"
          ]
        }
      ],
      "source": [
        "prompt=\" Résumez cet article \\n<article>: Deux images, et un sujet central : l’Ukraine. La journée du jeudi 13 mars a été marquée par un dialogue public à distance entre Vladimir Poutine et Donald Trump. Accueillant à Moscou son homologue biélorusse, Alexandre Loukachenko, le président russe a acquiescé du bout des lèvres, et sous conditions, à la proposition de cessez-le-feu de trente jours, avancée par la Maison Blanche et validée par Kiev. Pendant ce temps, à Washington, Donald Trump recevait le secrétaire général de l’OTAN, Mark Rutte. Le rapprochement américano-russe et l’acception conditionnée de la solidarité entre alliés, prisée par le milliardaire, inquiètent fortement les membres européens de l’Alliance atlantique. Au terme de cette journée, ni la paix en Ukraine ni l’avenir de l’OTAN ne se dessinent plus clairement.\\n<résumé>:\"\n",
        "print(prompt)\n",
        "\n",
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config.do_sample = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jpBcRaNJ2Xv",
        "outputId": "ad66af68-82e0-48c6-8fbb-bbdfd4d0f98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Résumez cet article \n",
            "<article>: Deux images, et un sujet central : l’Ukraine. La journée du jeudi 13 mars a été marquée par un dialogue public à distance entre Vladimir Poutine et Donald Trump. Accueillant à Moscou son homologue biélorusse, Alexandre Loukachenko, le président russe a acquiescé du bout des lèvres, et sous conditions, à la proposition de cessez-le-feu de trente jours, avancée par la Maison Blanche et validée par Kiev. Pendant ce temps, à Washington, Donald Trump recevait le secrétaire général de l’OTAN, Mark Rutte. Le rapprochement américano-russe et l’acception conditionnée de la solidarité entre alliés, prisée par le milliardaire, inquiètent fortement les membres européens de l’Alliance atlantique. Au terme de cette journée, ni la paix en Ukraine ni l’avenir de l’OTAN ne se dessinent plus clairement.\n",
            "<résumé>: C'est une histoire d'histoire politique qui démarre avec l'entrée au pouvoir de Vladimir Poutine, le 24 janvier 2015, dans l'émeute de l'URSS, et qui s'acheit avec la signature du accord de cesser le conflit à Moscou, et la signature du pacte de solidarité pour l'Europe. L'accent est mis sur la place de la Russie dans l'alliance européenne, dont l'image de pétitionur, et sur la situation économique de l'UE. Dans l'objectif de cette histoire, la Russie reste à l'avantage stratégique, car elle est à la fois un pétionnaire et un pétitionier, et comme l'a fait remarquer la France, il y a une relation commerciale entre l'URSS et l'URSS. Il existe deux autres sources de soutien : la France, qui est à l\n",
            "CPU times: user 2.3 s, sys: 2.13 ms, total: 2.3 s\n",
            "Wall time: 2.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:22:28.873416Z",
          "iopub.status.busy": "2025-03-13T19:22:28.873098Z",
          "iopub.status.idle": "2025-03-13T19:22:35.047639Z",
          "shell.execute_reply": "2025-03-13T19:22:35.046798Z",
          "shell.execute_reply.started": "2025-03-13T19:22:28.873396Z"
        },
        "id": "AtRdYaIO5bow",
        "outputId": "c5049009-2689-42aa-a50a-566391e0bdce",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set: 4000 examples\n",
            "Validation Set: 500 examples\n",
            "Test Set: 500 examples\n"
          ]
        }
      ],
      "source": [
        "ds = pd.read_csv(\"summary_dataset.csv\")\n",
        "train_ds, temp_ds = ds.train_test_split(test_size=0.2).values()  # 80% train, 20% temp\n",
        "valid_ds, test_ds = temp_ds.train_test_split(test_size=0.5).values()  # Split temp into 50% validation, 50% test\n",
        "\n",
        "\n",
        "# Display the number of examples in each split\n",
        "print(f\"Training Set: {len(train_ds)} examples\")\n",
        "print(f\"Validation Set: {len(valid_ds)} examples\")\n",
        "print(f\"Test Set: {len(test_ds)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 500/500 [17:46<00:00,  2.13s/ examples]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.77ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3212241"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summary(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \" Résumez cet article \\n<article>: \"+prompt+ \"\\n<résumé>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-no-shot'] = summary\n",
        "    return example\n",
        "\n",
        "# Iterate over the dataset and generate summaries\n",
        "test_ds=test_ds.map(generate_summary)\n",
        "# Save the modified dataset with the new column\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_noshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 500/500 [16:41<00:00,  2.00s/ examples]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.87ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5149558"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryO(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \"Voici l'exemples d' un article et son résumé :\\n Article : Un réseau d'escrocs qui revendait des voitures de luxe achetées frauduleusement a été démantelé. L'opération a mobilisé 90 gendarmes en Gironde, dans le Var et les Pyrénées-Orientales. Dix suspects ont été arrêtés, avec un préjudice total de 2 millions d'euros.\\n Résumé : Dix personnes arrêtées après une enquête sur une escroquerie aux voitures de luxe, causant un préjudice de 2 millions d’euros.\\nMaintenant résumez cet article \\n<article>: \"+prompt+ \"\\n<résumé>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-one-shot'] = summary\n",
        "    return example\n",
        "test_ds=test_ds.map(generate_summaryO)\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_oneshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 500/500 [15:22<00:00,  1.85s/ examples]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.20ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7236904"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryF(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \"Voici des exemples d'articles et leurs résumés : \\nArticle : Un réseau d'escrocs qui revendait des voitures de luxe achetées frauduleusement a été démantelé. L'opération a mobilisé 90 gendarmes en Gironde, dans le Var et les Pyrénées-Orientales. Dix suspects ont été arrêtés, avec un préjudice total de 2 millions d'euros. \\n Résumé : Dix personnes arrêtées après une enquête sur une escroquerie aux voitures de luxe, causant un préjudice de 2 millions d’euros. \\n Article : La saison 7 de Danse avec les stars s'est terminée, mais la saison 8 pourrait voir un changement majeur. Marie-Claude Pietragalla, juge depuis 2012, a indiqué qu'elle pourrait ne pas revenir en raison d'un emploi du temps chargé. \\n Résumé :  Marie-Claude Pietragalla pourrait quitter Danse avec les stars avant la saison 8. \\n Maintenant, résumez cet article \\n<article>: \"+prompt+ \"\\n<résumé>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['previous-summary-few-shot'] = summary\n",
        "    return example\n",
        "test_ds=test_ds.map(generate_summaryF)\n",
        "test_ds.to_csv(\"orangesum_with_summary_base_model_fewshot.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "caa6ca5074524b3bae5c8667a9930521",
            "047a977317f64641839e2d861fce9730",
            "4cbb1d7a496d41179d3bacde7a551563",
            "b12fc8b7eb6b463a817991002b43c261",
            "8a5ff2881388447eb1aba2e3f7766a29",
            "4eeb409d7a184a0494413d679e634281",
            "53bf697901c54486a43346083b6f5285",
            "4f7b44a7c46b4ae69b6af33c5e94ef45",
            "a43f0fa14008411885d60700ff1957d0",
            "8e2a146d4bbf4c49b35c29885339cb8b",
            "6a00d3e34d8845c9a500094c97db08d4",
            "446820aff94d4439ad2900251021d9cc",
            "f126dad02865462a84b27bd53e06a320",
            "3d58d5037dc54b1db37f7b9f58e2465a",
            "39a1b029dc3e4e61905324c2d0a0bcad",
            "4744462f25bb43b988269fdd1ab5e5d4",
            "3ca111d692fc4bed8d5e334e716b026a",
            "3b65c7213baa4a2586657e991751ac99",
            "b67893fb4aab4e06b204711c385543ac",
            "643bf294f441452fa12e23d52d7f751b",
            "7bc5197a69e74ecf8ea9848889bcb9ab",
            "37dd673aca5c4e7ab573fdc68a341f76"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:23:59.098340Z",
          "iopub.status.busy": "2025-03-13T19:23:59.098027Z",
          "iopub.status.idle": "2025-03-13T19:24:05.775480Z",
          "shell.execute_reply": "2025-03-13T19:24:05.774780Z",
          "shell.execute_reply.started": "2025-03-13T19:23:59.098315Z"
        },
        "id": "O6g5ncU84tUC",
        "outputId": "a9488a47-dff5-4465-8512-266f9ef14a98",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 4000/4000 [00:07<00:00, 547.00 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 559.97 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = f\"Résumez cet article,\\n<article>: {data_point['text']}\\n<résumé>:\"\n",
        "    response = f\" {data_point['generated-summary']}\"  \n",
        "\n",
        "    full_prompt_with_response = full_prompt + response + tokenizer.eos_token  # Append response + EOS token\n",
        "    tokenized_full_prompt = tokenizer(\n",
        "        full_prompt_with_response,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "        max_length=512\n",
        "    )\n",
        "    labels = tokenized_full_prompt.input_ids.clone()\n",
        "    end_prompt_idx = len(tokenizer(full_prompt)['input_ids']) \n",
        "    labels[:, :end_prompt_idx] = -100\n",
        "    return {\n",
        "        'input_ids': tokenized_full_prompt.input_ids.flatten(),\n",
        "        'labels': labels.flatten(),\n",
        "        'attention_mask': tokenized_full_prompt.attention_mask.flatten(),\n",
        "    }\n",
        "train_dataset = train_ds.shuffle(seed=42).map(generate_and_tokenize_prompt)\n",
        "val_dataset=valid_ds.shuffle(seed=42).map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-13T19:30:14.955887Z",
          "iopub.status.busy": "2025-03-13T19:30:14.955430Z",
          "iopub.status.idle": "2025-03-13T19:30:14.959717Z",
          "shell.execute_reply": "2025-03-13T19:30:14.958810Z",
          "shell.execute_reply.started": "2025-03-13T19:30:14.955850Z"
        },
        "id": "bL41MwIm6V4I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "execution": {
          "iopub.execute_input": "2025-03-13T19:33:11.358356Z",
          "iopub.status.busy": "2025-03-13T19:33:11.358064Z",
          "iopub.status.idle": "2025-03-13T19:33:12.957427Z",
          "shell.execute_reply": "2025-03-13T19:33:12.955903Z",
          "shell.execute_reply.started": "2025-03-13T19:33:11.358337Z"
        },
        "id": "noQU1h9k5djr",
        "outputId": "e0aa03fd-27e3-4e2d-e815-ca921b3d3c3a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/eleves-a/2024/christelle.clervilsson/.local/lib/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipykernel_2576282/4172712129.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 09:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.967800</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.301100</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.131900</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=750, training_loss=2.364438761393229, metrics={'train_runtime': 576.1801, 'train_samples_per_second': 20.827, 'train_steps_per_second': 1.302, 'total_flos': 1.3302272360448e+16, 'train_loss': 2.364438761393229, 'epoch': 3.0})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir='./results',\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    adam_epsilon=1e-8,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.999,\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=500,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='loss',\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "\n",
        ")\n",
        "model.config.use_cache = False\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEGzXnsWv_Dx",
        "outputId": "66a7384c-83c5-4c02-8c49-476a84d02f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./saved_model23_tokenizer-Instruct/tokenizer_config.json',\n",
              " './saved_model23_tokenizer-Instruct/special_tokens_map.json',\n",
              " './saved_model23_tokenizer-Instruct/vocab.json',\n",
              " './saved_model23_tokenizer-Instruct/merges.txt',\n",
              " './saved_model23_tokenizer-Instruct/added_tokens.json',\n",
              " './saved_model23_tokenizer-Instruct/tokenizer.json')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"./saved_model23\")\n",
        "tokenizer.save_pretrained(\"./saved_model23_tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Oz7tREn87glX"
      },
      "outputs": [],
      "source": [
        "prompt=\" Résumez cet article \\n<article>: Deux images, et un sujet central : l’Ukraine. La journée du jeudi 13 mars a été marquée par un dialogue public à distance entre Vladimir Poutine et Donald Trump. Accueillant à Moscou son homologue biélorusse, Alexandre Loukachenko, le président russe a acquiescé du bout des lèvres, et sous conditions, à la proposition de cessez-le-feu de trente jours, avancée par la Maison Blanche et validée par Kiev. Pendant ce temps, à Washington, Donald Trump recevait le secrétaire général de l’OTAN, Mark Rutte. Le rapprochement américano-russe et l’acception conditionnée de la solidarité entre alliés, prisée par le milliardaire, inquiètent fortement les membres européens de l’Alliance atlantique. Au terme de cette journée, ni la paix en Ukraine ni l’avenir de l’OTAN ne se dessinent plus clairement.\\n<résumé>:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRQZFfyP7fQO",
        "outputId": "cf7c3ea8-bf71-4ba9-987f-530ccd62de2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Résumez cet article \n",
            "<article>: Deux images, et un sujet central : l’Ukraine. La journée du jeudi 13 mars a été marquée par un dialogue public à distance entre Vladimir Poutine et Donald Trump. Accueillant à Moscou son homologue biélorusse, Alexandre Loukachenko, le président russe a acquiescé du bout des lèvres, et sous conditions, à la proposition de cessez-le-feu de trente jours, avancée par la Maison Blanche et validée par Kiev. Pendant ce temps, à Washington, Donald Trump recevait le secrétaire général de l’OTAN, Mark Rutte. Le rapprochement américano-russe et l’acception conditionnée de la solidarité entre alliés, prisée par le milliardaire, inquiètent fortement les membres européens de l’Alliance atlantique. Au terme de cette journée, ni la paix en Ukraine ni l’avenir de l’OTAN ne se dessinent plus clairement.\n",
            "<résumé>: Le 13 mars 2021, le président russe Vladimir Poutine a déclaré à Washington que la Ukraine serait « déployée à la frontière de l’Europe ». Le Kremlin a présenté la cessez-le-feu de trente jours comme une garantie de paix. La Maison Blanche a accepté la proposition de cessez-le-feu, mais ne s’est pas rendu compte de la solidarité entre alliés. Le président russe a déclaré que la Ukraine était « déployée à la frontière de l’Europe » et que la Russie était « à la frontière de l’Europe ».\n",
            "CPU times: user 1.65 s, sys: 5.06 ms, total: 1.66 s\n",
            "Wall time: 1.66 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOfD-Glc9ItN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 500/500 [19:41<00:00,  2.36s/ examples]\n",
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.20ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3256199"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_summaryFT(example):\n",
        "    prompt= example['text']\n",
        "    encoding = tokenizer( \" Résumez cet article \\n<article>: \"+prompt+ \"\\n<résumé>:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    summary =tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    example['current-summary'] = summary\n",
        "    return example\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "test_ds=test_ds.map(generate_summaryFT)\n",
        "test_ds.to_csv(\"orangesum_with_summary_afterfinetuning-Instruct.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "047a977317f64641839e2d861fce9730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eeb409d7a184a0494413d679e634281",
            "placeholder": "​",
            "style": "IPY_MODEL_53bf697901c54486a43346083b6f5285",
            "value": "Map: 100%"
          }
        },
        "37dd673aca5c4e7ab573fdc68a341f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a1b029dc3e4e61905324c2d0a0bcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc5197a69e74ecf8ea9848889bcb9ab",
            "placeholder": "​",
            "style": "IPY_MODEL_37dd673aca5c4e7ab573fdc68a341f76",
            "value": " 500/500 [00:03&lt;00:00, 145.68 examples/s]"
          }
        },
        "3b65c7213baa4a2586657e991751ac99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ca111d692fc4bed8d5e334e716b026a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d58d5037dc54b1db37f7b9f58e2465a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67893fb4aab4e06b204711c385543ac",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_643bf294f441452fa12e23d52d7f751b",
            "value": 500
          }
        },
        "446820aff94d4439ad2900251021d9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f126dad02865462a84b27bd53e06a320",
              "IPY_MODEL_3d58d5037dc54b1db37f7b9f58e2465a",
              "IPY_MODEL_39a1b029dc3e4e61905324c2d0a0bcad"
            ],
            "layout": "IPY_MODEL_4744462f25bb43b988269fdd1ab5e5d4"
          }
        },
        "4744462f25bb43b988269fdd1ab5e5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbb1d7a496d41179d3bacde7a551563": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7b44a7c46b4ae69b6af33c5e94ef45",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43f0fa14008411885d60700ff1957d0",
            "value": 4000
          }
        },
        "4eeb409d7a184a0494413d679e634281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7b44a7c46b4ae69b6af33c5e94ef45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bf697901c54486a43346083b6f5285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "643bf294f441452fa12e23d52d7f751b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a00d3e34d8845c9a500094c97db08d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc5197a69e74ecf8ea9848889bcb9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5ff2881388447eb1aba2e3f7766a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2a146d4bbf4c49b35c29885339cb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43f0fa14008411885d60700ff1957d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b12fc8b7eb6b463a817991002b43c261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e2a146d4bbf4c49b35c29885339cb8b",
            "placeholder": "​",
            "style": "IPY_MODEL_6a00d3e34d8845c9a500094c97db08d4",
            "value": " 4000/4000 [00:29&lt;00:00, 130.82 examples/s]"
          }
        },
        "b67893fb4aab4e06b204711c385543ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa6ca5074524b3bae5c8667a9930521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_047a977317f64641839e2d861fce9730",
              "IPY_MODEL_4cbb1d7a496d41179d3bacde7a551563",
              "IPY_MODEL_b12fc8b7eb6b463a817991002b43c261"
            ],
            "layout": "IPY_MODEL_8a5ff2881388447eb1aba2e3f7766a29"
          }
        },
        "f126dad02865462a84b27bd53e06a320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca111d692fc4bed8d5e334e716b026a",
            "placeholder": "​",
            "style": "IPY_MODEL_3b65c7213baa4a2586657e991751ac99",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
